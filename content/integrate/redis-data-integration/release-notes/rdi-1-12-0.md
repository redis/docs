---
Title: Redis Data Integration release notes 1.12.0 (June 2025)
alwaysopen: false
categories:
- docs
- operate
- rs
description: |
  Enhanced CLI command for HA topology information.
  Automatic DLQ routing for key errors.
  Enhanced transformation job validation in the PATCH and POST /api/v1/pipelines endpoints.
  Added `xml_to_dict` transformation function.
linkTitle: 1.12.0 (June 2025)
toc: 'true'
weight: 982
---

{{< note >}}This minor release replaces the 1.10.0 release.{{< /note >}}

RDIâ€™s mission is to help Redis customers sync Redis Enterprise with live data from their slow disk-based databases to:

- Meet the required speed and scale of read queries and provide an excellent and predictable user experience.
- Save resources and time when building pipelines and coding data transformations.
- Reduce the total cost of ownership by saving money on expensive database read replicas.

RDI keeps the Redis cache up to date with changes in the primary database, using a [_Change Data Capture (CDC)_](https://en.wikipedia.org/wiki/Change_data_capture) mechanism.
It also lets you _transform_ the data from relational tables into convenient and fast data structures that match your app's requirements. You specify the transformations using a configuration system, so no coding is required.

## Headlines

- Enhanced CLI status command to display RDI High Availability (HA) topology information.
- Improved error handling with automatic DLQ routing for wrong Redis key errors.
- Enhanced transformation job validation in the `PATCH` and `POST` `/api/v1/pipelines`
  endpoints with better error reporting.
- Added `xml_to_dict` transformation function for converting XML strings to JSON objects.

## Detailed changes

**CLI and Monitoring**

- The `redis-di status` command now displays High Availability (HA) information for cluster status visibility.
- Fixed `rdi_version_info` metric to export periodically instead of only at startup.
- Status API: Fixed issue - pipeline status not shifting from snapshot to streaming after restart or reset

**Validation and Error Handling**

- Static configuration and job schema validation provides clearer error messages.
- Pipeline endpoints validate source and job configurations against database metadata, preventing mismatches:
  - Error in table names or table doesn't exist.
  - More than one job per table.
- Automatic DLQ routing for wrong Redis key errors.
- Support for secret rotation. Pods are recreated when a secret rotates.
- RDI validates that its Redis database is not sharded when RDI starts.

**Database Connectivity**

- MySQL connector filters system tables for cleaner metadata.
- Collector API supports multiple database and schema entries for multi-database scenarios.
- `/api/v1/pipelines/{source_name}/metadata` endpoint supports table name filtering.
- `/api/v1/pipelines/{source_name}/tables` endpoint supports table name filtering.

**API and Infrastructure**

- Pipeline endpoints (source, targets, secret-providers) support key deletion via `PATCH` operations.
- Helm chart supports lists of ingress hosts.
- Operator handles missing SPCPS CRD gracefully.

## Limitations

RDI can write data to a Redis Active-Active database. However, it doesn't support writing data to two or more Active-Active replicas. Writing data from RDI to several Active-Active replicas could easily harm data integrity as RDI is not synchronous with the source database commits.
