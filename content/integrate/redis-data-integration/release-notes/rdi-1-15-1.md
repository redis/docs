---
Title: Redis Data Integration release notes 1.15.1 (August 2025)
alwaysopen: false
categories:
- docs
- operate
- rs
description: |
  New RDI API v2 with enhanced pipeline management.
  Improved Oracle RAC support with configuration scaffolding.
  Enhanced metrics and monitoring capabilities.
  Better TLS/mTLS support across components.
linkTitle: 1.15.1 (August 2025)
toc: 'true'
weight: 975
---

{{< note >}}This maintenance release replaces the 1.15.0 release.{{< /note >}}

RDIâ€™s mission is to help Redis customers sync Redis Enterprise with live data from their slow disk-based databases to:

- Meet the required speed and scale of read queries and provide an excellent and predictable user experience.
- Save resources and time when building pipelines and coding data transformations.
- Reduce the total cost of ownership by saving money on expensive database read replicas.

RDI keeps the Redis cache up to date with changes in the primary database, using a [_Change Data Capture (CDC)_](https://en.wikipedia.org/wiki/Change_data_capture) mechanism.
It also lets you _transform_ the data from relational tables into convenient and fast data structures that match your app's requirements. You specify the transformations using a configuration system, so no coding is required.

## What's New in 1.15.1

- Fix dump support package problems
  - Fix improper namespace passing to the kubectl command
  - Mask passwords from sensitive configs
  - Dump masked pipeline information
  - Mask and dump audit logs collected from RDI DB rdi:tasks streams
- Processor performance improvements - Increase throughput by ~50% during initial sync
  - The processor now uses parallel processing to improve performance - reading from source, writing to target and acknowledging the processed data is now done in parallel.
  - Added parameter - `read_batch_timeout_ms` to the processor configuration to control the timeout for reading from the RDI streams. The default is 100ms.
  - `read_batch_size` is now functional. In previous versions, the processor would always read a batch size of 2000 from the stream, regardless of the `read_batch_size` value.

## Limitations

RDI can write data to a Redis Active-Active database. However, it doesn't support writing data to two or more Active-Active replicas. Writing data from RDI to several Active-Active replicas could easily harm data integrity as RDI is not synchronous with the source database commits.
